{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a8ee00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# natural lang tool kit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "466962bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data,[1][2] and apply knowledge from data across a broad range of application domains. Data science is related to data mining, machine learning and big data.\n",
    "\n",
    "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.[3] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[4] However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[5][6]\n",
    "\n",
    "A data scientist is someone who creates programming code and combines it with statistical knowledge to create insights from data.[7\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc8bcf3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data,[1][2] and apply knowledge from data across a broad range of application domains.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b07a4249",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.sent_tokenize(text)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62ba0e61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'an',\n",
       " 'interdisciplinary',\n",
       " 'field',\n",
       " 'that',\n",
       " 'uses',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " ',',\n",
       " 'processes',\n",
       " ',',\n",
       " 'algorithms',\n",
       " 'and',\n",
       " 'systems',\n",
       " 'to',\n",
       " 'extract',\n",
       " 'knowledge',\n",
       " 'and',\n",
       " 'insights',\n",
       " 'from',\n",
       " 'noisy',\n",
       " ',',\n",
       " 'structured',\n",
       " 'and',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " ',',\n",
       " '[',\n",
       " '1',\n",
       " ']',\n",
       " '[',\n",
       " '2',\n",
       " ']',\n",
       " 'and',\n",
       " 'apply',\n",
       " 'knowledge',\n",
       " 'from',\n",
       " 'data',\n",
       " 'across',\n",
       " 'a',\n",
       " 'broad',\n",
       " 'range',\n",
       " 'of',\n",
       " 'application',\n",
       " 'domains',\n",
       " '.',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'related',\n",
       " 'to',\n",
       " 'data',\n",
       " 'mining',\n",
       " ',',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'and',\n",
       " 'big',\n",
       " 'data',\n",
       " '.',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'a',\n",
       " '``',\n",
       " 'concept',\n",
       " 'to',\n",
       " 'unify',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'data',\n",
       " 'analysis',\n",
       " ',',\n",
       " 'informatics',\n",
       " ',',\n",
       " 'and',\n",
       " 'their',\n",
       " 'related',\n",
       " 'methods',\n",
       " \"''\",\n",
       " 'in',\n",
       " 'order',\n",
       " 'to',\n",
       " '``',\n",
       " 'understand',\n",
       " 'and',\n",
       " 'analyse',\n",
       " 'actual',\n",
       " 'phenomena',\n",
       " \"''\",\n",
       " 'with',\n",
       " 'data',\n",
       " '.',\n",
       " '[',\n",
       " '3',\n",
       " ']',\n",
       " 'It',\n",
       " 'uses',\n",
       " 'techniques',\n",
       " 'and',\n",
       " 'theories',\n",
       " 'drawn',\n",
       " 'from',\n",
       " 'many',\n",
       " 'fields',\n",
       " 'within',\n",
       " 'the',\n",
       " 'context',\n",
       " 'of',\n",
       " 'mathematics',\n",
       " ',',\n",
       " 'statistics',\n",
       " ',',\n",
       " 'computer',\n",
       " 'science',\n",
       " ',',\n",
       " 'information',\n",
       " 'science',\n",
       " ',',\n",
       " 'and',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " '.',\n",
       " '[',\n",
       " '4',\n",
       " ']',\n",
       " 'However',\n",
       " ',',\n",
       " 'data',\n",
       " 'science',\n",
       " 'is',\n",
       " 'different',\n",
       " 'from',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'and',\n",
       " 'information',\n",
       " 'science',\n",
       " '.',\n",
       " 'Turing',\n",
       " 'Award',\n",
       " 'winner',\n",
       " 'Jim',\n",
       " 'Gray',\n",
       " 'imagined',\n",
       " 'data',\n",
       " 'science',\n",
       " 'as',\n",
       " 'a',\n",
       " '``',\n",
       " 'fourth',\n",
       " 'paradigm',\n",
       " \"''\",\n",
       " 'of',\n",
       " 'science',\n",
       " '(',\n",
       " 'empirical',\n",
       " ',',\n",
       " 'theoretical',\n",
       " ',',\n",
       " 'computational',\n",
       " ',',\n",
       " 'and',\n",
       " 'now',\n",
       " 'data-driven',\n",
       " ')',\n",
       " 'and',\n",
       " 'asserted',\n",
       " 'that',\n",
       " '``',\n",
       " 'everything',\n",
       " 'about',\n",
       " 'science',\n",
       " 'is',\n",
       " 'changing',\n",
       " 'because',\n",
       " 'of',\n",
       " 'the',\n",
       " 'impact',\n",
       " 'of',\n",
       " 'information',\n",
       " 'technology',\n",
       " \"''\",\n",
       " 'and',\n",
       " 'the',\n",
       " 'data',\n",
       " 'deluge',\n",
       " '.',\n",
       " '[',\n",
       " '5',\n",
       " ']',\n",
       " '[',\n",
       " '6',\n",
       " ']',\n",
       " 'A',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'is',\n",
       " 'someone',\n",
       " 'who',\n",
       " 'creates',\n",
       " 'programming',\n",
       " 'code',\n",
       " 'and',\n",
       " 'combines',\n",
       " 'it',\n",
       " 'with',\n",
       " 'statistical',\n",
       " 'knowledge',\n",
       " 'to',\n",
       " 'create',\n",
       " 'insights',\n",
       " 'from',\n",
       " 'data',\n",
       " '.',\n",
       " '[',\n",
       " '7']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2238fb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "text1 = \"we are trying to test  nltk lib, in this class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1263ddc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bfbc9b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "tokens: expected a list of strings, got a string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-44b552c2acc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m    165\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[1;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[0;32m    118\u001b[0m     \u001b[1;31m# Throws Error if tokens is of string type\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokens: expected a list of strings, got a string\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: tokens: expected a list of strings, got a string"
     ]
    }
   ],
   "source": [
    "nltk.pos_tag(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec6fb663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('we', 'PRP'),\n",
       " ('are', 'VBP'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('test', 'VB'),\n",
       " ('nltk', 'JJ'),\n",
       " ('lib', 'NN'),\n",
       " (',', ','),\n",
       " ('in', 'IN'),\n",
       " ('this', 'DT'),\n",
       " ('class', 'NN')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(nltk.word_tokenize(text1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2473ee9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a98dfe09",
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No such file or directory: 'C:\\\\Users\\\\anand\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords\\\\hindi'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-f2be020ee93a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'hindi'\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# we need to instal hindi corpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\wordlist.py\u001b[0m in \u001b[0;36mwords\u001b[1;34m(self, fileids, ignore_lines_startswith)\u001b[0m\n\u001b[0;32m     19\u001b[0m         return [\n\u001b[0;32m     20\u001b[0m             \u001b[0mline\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mline_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfileids\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mignore_lines_startswith\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         ]\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mraw\u001b[1;34m(self, fileids)\u001b[0m\n\u001b[0;32m    216\u001b[0m         \u001b[0mcontents\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfileids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m                 \u001b[0mcontents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\corpus\\reader\\api.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, file)\u001b[0m\n\u001b[0;32m    229\u001b[0m         \"\"\"\n\u001b[0;32m    230\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[0mstream\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_root\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mjoin\u001b[1;34m(self, fileid)\u001b[0m\n\u001b[0;32m    332\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfileid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 334\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mFileSystemPathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\compat.py\u001b[0m in \u001b[0;36m_decorator\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_decorator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madd_py3_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0minit_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_decorator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, _path)\u001b[0m\n\u001b[0;32m    310\u001b[0m         \u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    311\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 312\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No such file or directory: %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    313\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: No such file or directory: 'C:\\\\Users\\\\anand\\\\AppData\\\\Roaming\\\\nltk_data\\\\corpora\\\\stopwords\\\\hindi'"
     ]
    }
   ],
   "source": [
    "stopwords.words('hindi')  # we need to instal hindi corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "058f48a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "punch = string.punctuation\n",
    "stop_word = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5fa1e445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all the stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a4d445f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data,[1][2] and apply knowledge from data across a broad range of application domains. Data science is related to data mining, machine learning and big data.\n",
    "\n",
    "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.[3] It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge.[4] However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[5][6]\n",
    "\n",
    "A data scientist is someone who creates programming code and combines it with statistical knowledge to create insights from data.[7\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "509942d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for word in nltk.word_tokenize(text):\n",
    "    if word not in punch:\n",
    "        if word not in stop_word:\n",
    "            l.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d83ee614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data',\n",
       " 'science',\n",
       " 'interdisciplinary',\n",
       " 'field',\n",
       " 'uses',\n",
       " 'scientific',\n",
       " 'methods',\n",
       " 'processes',\n",
       " 'algorithms',\n",
       " 'systems',\n",
       " 'extract',\n",
       " 'knowledge',\n",
       " 'insights',\n",
       " 'noisy',\n",
       " 'structured',\n",
       " 'unstructured',\n",
       " 'data',\n",
       " '1',\n",
       " '2',\n",
       " 'apply',\n",
       " 'knowledge',\n",
       " 'data',\n",
       " 'across',\n",
       " 'broad',\n",
       " 'range',\n",
       " 'application',\n",
       " 'domains',\n",
       " 'Data',\n",
       " 'science',\n",
       " 'related',\n",
       " 'data',\n",
       " 'mining',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'big',\n",
       " 'data',\n",
       " 'Data',\n",
       " 'science',\n",
       " '``',\n",
       " 'concept',\n",
       " 'unify',\n",
       " 'statistics',\n",
       " 'data',\n",
       " 'analysis',\n",
       " 'informatics',\n",
       " 'related',\n",
       " 'methods',\n",
       " \"''\",\n",
       " 'order',\n",
       " '``',\n",
       " 'understand',\n",
       " 'analyse',\n",
       " 'actual',\n",
       " 'phenomena',\n",
       " \"''\",\n",
       " 'data',\n",
       " '3',\n",
       " 'It',\n",
       " 'uses',\n",
       " 'techniques',\n",
       " 'theories',\n",
       " 'drawn',\n",
       " 'many',\n",
       " 'fields',\n",
       " 'within',\n",
       " 'context',\n",
       " 'mathematics',\n",
       " 'statistics',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'information',\n",
       " 'science',\n",
       " 'domain',\n",
       " 'knowledge',\n",
       " '4',\n",
       " 'However',\n",
       " 'data',\n",
       " 'science',\n",
       " 'different',\n",
       " 'computer',\n",
       " 'science',\n",
       " 'information',\n",
       " 'science',\n",
       " 'Turing',\n",
       " 'Award',\n",
       " 'winner',\n",
       " 'Jim',\n",
       " 'Gray',\n",
       " 'imagined',\n",
       " 'data',\n",
       " 'science',\n",
       " '``',\n",
       " 'fourth',\n",
       " 'paradigm',\n",
       " \"''\",\n",
       " 'science',\n",
       " 'empirical',\n",
       " 'theoretical',\n",
       " 'computational',\n",
       " 'data-driven',\n",
       " 'asserted',\n",
       " '``',\n",
       " 'everything',\n",
       " 'science',\n",
       " 'changing',\n",
       " 'impact',\n",
       " 'information',\n",
       " 'technology',\n",
       " \"''\",\n",
       " 'data',\n",
       " 'deluge',\n",
       " '5',\n",
       " '6',\n",
       " 'A',\n",
       " 'data',\n",
       " 'scientist',\n",
       " 'someone',\n",
       " 'creates',\n",
       " 'programming',\n",
       " 'code',\n",
       " 'combines',\n",
       " 'statistical',\n",
       " 'knowledge',\n",
       " 'create',\n",
       " 'insights',\n",
       " 'data',\n",
       " '7']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "09a007d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Data', 'NNP'),\n",
       " ('science', 'NN'),\n",
       " ('interdisciplinary', 'JJ'),\n",
       " ('field', 'NN'),\n",
       " ('uses', 'VBZ'),\n",
       " ('scientific', 'JJ'),\n",
       " ('methods', 'NNS'),\n",
       " ('processes', 'VBZ'),\n",
       " ('algorithms', 'JJ'),\n",
       " ('systems', 'NNS'),\n",
       " ('extract', 'JJ'),\n",
       " ('knowledge', 'JJ'),\n",
       " ('insights', 'NNS'),\n",
       " ('noisy', 'RB'),\n",
       " ('structured', 'VBD'),\n",
       " ('unstructured', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('1', 'CD'),\n",
       " ('2', 'CD'),\n",
       " ('apply', 'NN'),\n",
       " ('knowledge', 'NN'),\n",
       " ('data', 'NNS'),\n",
       " ('across', 'IN'),\n",
       " ('broad', 'JJ'),\n",
       " ('range', 'NN'),\n",
       " ('application', 'NN'),\n",
       " ('domains', 'VBZ'),\n",
       " ('Data', 'NNP'),\n",
       " ('science', 'NN'),\n",
       " ('related', 'VBN'),\n",
       " ('data', 'NNS'),\n",
       " ('mining', 'NN'),\n",
       " ('machine', 'NN'),\n",
       " ('learning', 'VBG'),\n",
       " ('big', 'JJ'),\n",
       " ('data', 'NNS'),\n",
       " ('Data', 'NNP'),\n",
       " ('science', 'NN'),\n",
       " ('``', '``'),\n",
       " ('concept', 'JJ'),\n",
       " ('unify', 'JJ'),\n",
       " ('statistics', 'NNS'),\n",
       " ('data', 'NNS'),\n",
       " ('analysis', 'NN'),\n",
       " ('informatics', 'NNS'),\n",
       " ('related', 'JJ'),\n",
       " ('methods', 'NNS'),\n",
       " (\"''\", \"''\"),\n",
       " ('order', 'NN'),\n",
       " ('``', '``'),\n",
       " ('understand', 'JJ'),\n",
       " ('analyse', 'NN'),\n",
       " ('actual', 'JJ'),\n",
       " ('phenomena', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('data', 'NNS'),\n",
       " ('3', 'CD'),\n",
       " ('It', 'PRP'),\n",
       " ('uses', 'VBZ'),\n",
       " ('techniques', 'NNS'),\n",
       " ('theories', 'NNS'),\n",
       " ('drawn', 'VBP'),\n",
       " ('many', 'JJ'),\n",
       " ('fields', 'NNS'),\n",
       " ('within', 'IN'),\n",
       " ('context', 'NN'),\n",
       " ('mathematics', 'NNS'),\n",
       " ('statistics', 'NNS'),\n",
       " ('computer', 'NN'),\n",
       " ('science', 'NN'),\n",
       " ('information', 'NN'),\n",
       " ('science', 'NN'),\n",
       " ('domain', 'NN'),\n",
       " ('knowledge', 'NN'),\n",
       " ('4', 'CD'),\n",
       " ('However', 'RB'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'RB'),\n",
       " ('different', 'JJ'),\n",
       " ('computer', 'NN'),\n",
       " ('science', 'NN'),\n",
       " ('information', 'NN'),\n",
       " ('science', 'NN'),\n",
       " ('Turing', 'NNP'),\n",
       " ('Award', 'NNP'),\n",
       " ('winner', 'NN'),\n",
       " ('Jim', 'NNP'),\n",
       " ('Gray', 'NNP'),\n",
       " ('imagined', 'VBD'),\n",
       " ('data', 'NNS'),\n",
       " ('science', 'NN'),\n",
       " ('``', '``'),\n",
       " ('fourth', 'JJ'),\n",
       " ('paradigm', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('science', 'NN'),\n",
       " ('empirical', 'JJ'),\n",
       " ('theoretical', 'JJ'),\n",
       " ('computational', 'JJ'),\n",
       " ('data-driven', 'NN'),\n",
       " ('asserted', 'VBD'),\n",
       " ('``', '``'),\n",
       " ('everything', 'NN'),\n",
       " ('science', 'NN'),\n",
       " ('changing', 'VBG'),\n",
       " ('impact', 'JJ'),\n",
       " ('information', 'NN'),\n",
       " ('technology', 'NN'),\n",
       " (\"''\", \"''\"),\n",
       " ('data', 'NNS'),\n",
       " ('deluge', 'VBD'),\n",
       " ('5', 'CD'),\n",
       " ('6', 'CD'),\n",
       " ('A', 'NNP'),\n",
       " ('data', 'NNS'),\n",
       " ('scientist', 'NN'),\n",
       " ('someone', 'NN'),\n",
       " ('creates', 'VBZ'),\n",
       " ('programming', 'VBG'),\n",
       " ('code', 'NN'),\n",
       " ('combines', 'NNS'),\n",
       " ('statistical', 'JJ'),\n",
       " ('knowledge', 'NN'),\n",
       " ('create', 'NN'),\n",
       " ('insights', 'NNS'),\n",
       " ('data', 'NNS'),\n",
       " ('7', 'CD')]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd211597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer ,SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d8718acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter = PorterStemmer()\n",
    "lancas = LancasterStemmer()\n",
    "snow = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "13468906",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "84e716b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hobbi'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('hobbies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f6eb81b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'continu'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('continuous')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e08ff011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poornima'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('poornima')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2674aa20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fae3ace7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hobbi'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('hobbie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7abfd428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancas.stem('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f15189a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'comput'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('computer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "679af29a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('runs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f07e65b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'runi'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('runi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d40992ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poornima'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.stem('poornimaing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1f1c5840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poornima'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "porter.stem('poornimaing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3559cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poornima'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lancas.stem('poornimaing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c63ce464",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\anand\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\omw-1.4.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae79658a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemma = WordNetLemmatizer()\n",
    "lemma.lemmatize(\"running\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d3faea30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"run\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0008a42d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'went'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"went\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "05f4de70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gone'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"gone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c42f1de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"go\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233a22a5",
   "metadata": {},
   "source": [
    "  Lemma can convert word into  base word depends upon the parts of speech\n",
    "we have given in the code here v - verb. Lemmatize is a case sensitive\n",
    "\n",
    "Only lemmatizer converts our words into base word. Stem does not do this\n",
    "fucntion.Stem is used to chopp some of the characters like running to run etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e18c66c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"went\" , pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2e774de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma.lemmatize(\"gone\" , pos = 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0747e0e",
   "metadata": {},
   "source": [
    "conversion of text datasset into numerical "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01bde925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Data science is an interdisciplinary field that uses scientific methods, processes, algorithms and systems to extract knowledge and insights from noisy, structured and unstructured data,[1][2] and apply knowledge from data across a broad range of application domains. \"\"\"\n",
    "\n",
    "\"\"\"Data science is related to data mining, machine learning and big data.\n",
    "\n",
    "Data science is a \"concept to unify statistics, data analysis, informatics, and their related methods\" in order to \"understand and analyse actual phenomena\" with data.\"\"\"\n",
    "\n",
    "\"\"\"It uses techniques and theories drawn from many fields within the context of mathematics, statistics, computer science, information science, and domain knowledge. However, data science is different from computer science and information science. Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical, theoretical, computational, and now data-driven) and asserted that \"everything about science is changing because of the impact of information technology\" and the data deluge.[5][6]\n",
    "\n",
    "A data scientist is someone who creates programming code and combines it with statistical knowledge to create insights from data.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e43b12",
   "metadata": {},
   "source": [
    "To pass the above data into our model, first we need to convert it into\n",
    "structured numerical format.\n",
    "\n",
    "Above data is not in a structured format ( there are unequal no of words in each line). after cleaning the & , and other things like removing the stop word, stemming and lemmatizing, our first approch should be \n",
    "we should convert it into sturucred numerical ojbect.\n",
    "\n",
    "iN nlp EACH LINE IS CALLED AS DOCUMENT\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17926381",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF - IDF\n",
    "\n",
    "TF - TERM FREQ\n",
    "\n",
    "IDF - INVERSE DOCUMENT FREQUENCY\n",
    "\n",
    "\n",
    "         TERM i FREQ IN DOCUMENT j\n",
    " tf =    -----------------------\n",
    "         TOTAL WORDS IN DOC J\n",
    "    \n",
    "    \n",
    "            TOTAL DOCUMENT\n",
    "IDF = LOG2  ---------------\n",
    "            DOCUMENT WITH TERM J"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
